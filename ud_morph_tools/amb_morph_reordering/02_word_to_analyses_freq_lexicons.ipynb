{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on using word-to-analyses-freq lexicons for reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, os.path\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "from eval_utils import GoldStandard\n",
    "from eval_utils import add_normalized_form_to_words\n",
    "from eval_utils import collect_matches\n",
    "from eval_utils import write_out_freq_sorted_annotations\n",
    "from eval_utils import evaluate_reorderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus with gold standard annotations\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lexicons based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded and pre-annotated  et_edt-ud-train_015.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_016.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_017.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_018.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_019.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_020.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_021.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_022.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_023.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_024.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_025.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_026.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_027.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_028.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_029.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_030.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_031.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_032.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_033.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_034.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_035.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_036.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_037.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_038.json\n"
     ]
    }
   ],
   "source": [
    "# Load gold standard texts and add pre-annotations\n",
    "loaded_texts = []\n",
    "for fname in os.listdir( input_dir ):\n",
    "    if 'dev' in fname:\n",
    "        continue\n",
    "    if 'test' in fname:\n",
    "        continue\n",
    "    if fname.endswith('.json'):\n",
    "        # Load Text with gold standard annotations\n",
    "        text = json_to_text(file=os.path.join(input_dir, fname) )\n",
    "        if 'normalized_form' not in text.words.attributes:\n",
    "            add_normalized_form_to_words( text.words )\n",
    "        assert 'normalized_form' in text.words.attributes\n",
    "        # Add Vabamorf's default morph analysis\n",
    "        text.tag_layer(['morph_analysis'])\n",
    "        loaded_texts.append( text )\n",
    "        print(' Loaded and pre-annotated ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed documents:                                 24\n",
      " Ambiguous words from total words:                    28613 / 344646 (8.30%)\n",
      " Ambiguous words successfully matched to gold morph:  26774 / 28613 (93.57%)\n",
      " Ambiguous words with indistinguishable annotations:  159 / 28613 (0.56%)\n"
     ]
    }
   ],
   "source": [
    "focus_fields = ['lemma','ending','clitic','partofspeech','form']\n",
    "word_matches = collect_matches( loaded_texts, 'ud_morph_reduced', \n",
    "                                gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                                focus_fields = focus_fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all analyses\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                   word_matches, focus_fields, \n",
    "                                   freq_threshold=-1, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include analyses at freq threshold 5\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                    word_matches, focus_fields, \n",
    "                                    freq_threshold=5, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add lexicons based on train+dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded and pre-annotated  et_edt-ud-dev_000.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_001.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_002.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_003.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_004.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_005.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_006.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_007.json\n",
      " Loaded and pre-annotated  et_edt-ud-dev_008.json\n"
     ]
    }
   ],
   "source": [
    "assert loaded_texts and len(loaded_texts) > 0\n",
    "# Add dev data to loaded_texts\n",
    "for fname in os.listdir( input_dir ):\n",
    "    if 'train' in fname:\n",
    "        continue\n",
    "    if 'test' in fname:\n",
    "        continue\n",
    "    if fname.endswith('.json'):\n",
    "        # Load Text with gold standard annotations\n",
    "        text = json_to_text(file=os.path.join(input_dir, fname) )\n",
    "        if 'normalized_form' not in text.words.attributes:\n",
    "            add_normalized_form_to_words( text.words )\n",
    "        assert 'normalized_form' in text.words.attributes\n",
    "        # Add Vabamorf's default morph analysis\n",
    "        text.tag_layer(['morph_analysis'])\n",
    "        loaded_texts.append( text )\n",
    "        print(' Loaded and pre-annotated ', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Processed documents:                                 33\n",
      " Ambiguous words from total words:                    32346 / 389278 (8.31%)\n",
      " Ambiguous words successfully matched to gold morph:  30273 / 32346 (93.59%)\n",
      " Ambiguous words with indistinguishable annotations:  170 / 32346 (0.53%)\n"
     ]
    }
   ],
   "source": [
    "focus_fields = ['lemma','ending','clitic','partofspeech','form']\n",
    "word_matches = collect_matches( loaded_texts, 'ud_morph_reduced', \n",
    "                                gold_morph_type=GoldStandard.UD_CORPUS,\n",
    "                                focus_fields = focus_fields )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include all analyses\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_and_dev_sorted_analyses_full.csv', \n",
    "                                   word_matches, focus_fields, \n",
    "                                   freq_threshold=-1, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Include analyses at freq threshold 5\n",
    "write_out_freq_sorted_annotations( 'et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv', \n",
    "                                    word_matches, focus_fields, \n",
    "                                    freq_threshold=5, encoding='utf-8' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mail', [{'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}]),\n",
       "Span('üks', [{'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}, {'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from estnltk import Text\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "t=Text('See toimus 1. mail, ütles üks.')\n",
    "# Switch off applying reordered by default\n",
    "t.layer_resolver.update( VabamorfTagger(use_reorderer=False) )\n",
    "\n",
    "# Add morph without reorderer\n",
    "t.tag_layer('morph_analysis')\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>mail</td>\n",
       "      <td>mail</td>\n",
       "      <td>mai</td>\n",
       "      <td>mai</td>\n",
       "      <td>['mai']</td>\n",
       "      <td>l</td>\n",
       "      <td></td>\n",
       "      <td>sg ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>mail</td>\n",
       "      <td>maa</td>\n",
       "      <td>maa</td>\n",
       "      <td>['maa']</td>\n",
       "      <td>il</td>\n",
       "      <td></td>\n",
       "      <td>pl ad</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>üks</td>\n",
       "      <td>['üks']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('mail', [{'normalized_text': 'mail', 'lemma': 'mai', 'root': 'mai', 'root_tokens': ['mai'], 'ending': 'l', 'clitic': '', 'form': 'sg ad', 'partofspeech': 'S'}, {'normalized_text': 'mail', 'lemma': 'maa', 'root': 'maa', 'root_tokens': ['maa'], 'ending': 'il', 'clitic': '', 'form': 'pl ad', 'partofspeech': 'S'}]),\n",
       "Span('üks', [{'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'P'}, {'normalized_text': 'üks', 'lemma': 'üks', 'root': 'üks', 'root_tokens': ['üks'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'N'}])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to ordering\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "morph_reorderer.retag( t )\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train || eval data: dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 9 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           3733\n",
      "   -- correct analysis first:      1749 / 3733 (46.85%)\n",
      "   -- correct analysis not first:  1782 / 3733 (47.74%)\n",
      "   -- correct analysis not found:  234 / 3733 (6.27%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           3733\n",
      "   -- correct analysis first:      2759 / 3733 (73.91%)\n",
      "   -- correct analysis not first:  772 / 3733 (20.68%)\n",
      "   -- correct analysis not found:  234 / 3733 (6.27%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  1749 / 3733 (46.85%) ==> 2759 / 3733 (73.91%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'test'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 9 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           3733\n",
      "   -- correct analysis first:      1749 / 3733 (46.85%)\n",
      "   -- correct analysis not first:  1782 / 3733 (47.74%)\n",
      "   -- correct analysis not found:  234 / 3733 (6.27%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           3733\n",
      "   -- correct analysis first:      2702 / 3733 (72.38%)\n",
      "   -- correct analysis not first:  829 / 3733 (22.21%)\n",
      "   -- correct analysis not found:  234 / 3733 (6.27%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  1749 / 3733 (46.85%) ==> 2702 / 3733 (72.38%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'test'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train || eval data: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3037 / 4139 (73.38%)\n",
      "   -- correct analysis not first:  950 / 4139 (22.95%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3037 / 4139 (73.38%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3008 / 4139 (72.67%)\n",
      "   -- correct analysis not first:  979 / 4139 (23.65%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3008 / 4139 (72.67%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS,\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train and dev || eval data: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3043 / 4139 (73.52%)\n",
      "   -- correct analysis not first:  944 / 4139 (22.81%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3043 / 4139 (73.52%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_and_dev_sorted_analyses_full.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3012 / 4139 (72.77%)\n",
      "   -- correct analysis not first:  975 / 4139 (23.56%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3012 / 4139 (72.77%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer(reorderings_csv_file='et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv', \n",
    "                                         postag_freq_csv_file=None,\n",
    "                                         form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', \n",
    "                    gold_morph_type=GoldStandard.UD_CORPUS, \n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Evaluation using lexicons generated from UD corpus v2.5 (as of 2022-12-05):\n",
    "\n",
    "\n",
    "           lexicon file:                               eval: dev              eval: test\n",
    "\n",
    "    et_edt-ud-train_sorted_analyses_full.csv       46.85% --> 73.91%       50.71% -> 73.38%\n",
    "\n",
    "    et_edt-ud-train_sorted_analyses_cut_5.csv      46.85% --> 72.38%       50.71% -> 72.67%\n",
    "\n",
    "    et_edt-ud-train_and_dev_sorted_analyses_full.csv    --------           50.71% -> 73.52%\n",
    "\n",
    "    et_edt-ud-train_and_dev_sorted_analyses_cut_5.csv   --------           50.71% -> 72.77%\n",
    "                                                                          "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
