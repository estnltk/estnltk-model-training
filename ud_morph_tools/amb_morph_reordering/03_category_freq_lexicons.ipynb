{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments on using morph_analysis category frequency lexicons for reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import os, os.path\n",
    "from estnltk.converters import json_to_text\n",
    "from estnltk.taggers import MorphAnalysisReorderer\n",
    "\n",
    "from eval_utils import GoldStandard\n",
    "from eval_utils import add_normalized_form_to_words\n",
    "from eval_utils import write_out_freq_sorted_categories\n",
    "from eval_utils import collect_category_stats\n",
    "from eval_utils import evaluate_reorderer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corpus with gold standard annotations\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lexicons based on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded and pre-annotated  et_edt-ud-train_015.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_016.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_017.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_018.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_019.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_020.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_021.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_022.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_023.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_024.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_025.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_026.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_027.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_028.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_029.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_030.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_031.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_032.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_033.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_034.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_035.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_036.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_037.json\n",
      " Loaded and pre-annotated  et_edt-ud-train_038.json\n"
     ]
    }
   ],
   "source": [
    "# Load gold standard texts and add pre-annotations\n",
    "loaded_texts = []\n",
    "for fname in os.listdir( input_dir ):\n",
    "    if 'dev' in fname:\n",
    "        continue\n",
    "    if 'test' in fname:\n",
    "        continue\n",
    "    if fname.endswith('.json'):\n",
    "        # Load Text with gold standard annotations\n",
    "        text = json_to_text(file=os.path.join(input_dir, fname) )\n",
    "        if 'normalized_form' not in text.words.attributes:\n",
    "            add_normalized_form_to_words( text.words )\n",
    "        assert 'normalized_form' in text.words.attributes\n",
    "        # Add Vabamorf's default morph analysis\n",
    "        text.tag_layer('morph_analysis')\n",
    "        loaded_texts.append( text )\n",
    "        print(' Loaded and pre-annotated ', fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect category frequencies from all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Punctuation was excluded.\n",
      " Processed documents:                                 24\n",
      " Ambiguous words from total words:                    28613 / 288329 (9.92%)\n",
      " Words successfully matched to gold morph:            260156 / 288329 (90.23%)\n"
     ]
    }
   ],
   "source": [
    "pos_freq, form_freq = collect_category_stats( loaded_texts, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                                              collect_only_from_ambiguous=False)\n",
    "write_out_freq_sorted_categories('et_edt-ud-train_cat_postag_freq_all.csv', pos_freq, 'partofspeech')\n",
    "write_out_freq_sorted_categories('et_edt-ud-train_cat_form_freq_all.csv', form_freq, 'form')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collect category frequencies only from ambiguous words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Stats collected only from ambiguous words.\n",
      " Punctuation was excluded.\n",
      " Processed documents:                                 24\n",
      " Ambiguous words from total words:                    28613 / 28613 (100.00%)\n",
      " Words successfully matched to gold morph:            26774 / 28613 (93.57%)\n"
     ]
    }
   ],
   "source": [
    "pos_freq_a, form_freq_a = collect_category_stats( loaded_texts, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                                                  collect_only_from_ambiguous=True)\n",
    "write_out_freq_sorted_categories('et_edt-ud-train_cat_postag_freq_amb.csv', pos_freq_a, 'partofspeech')\n",
    "write_out_freq_sorted_categories('et_edt-ud-train_cat_form_freq_amb.csv', form_freq_a, 'form')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A small test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viitama</td>\n",
       "      <td>viita</td>\n",
       "      <td>['viita']</td>\n",
       "      <td>nud</td>\n",
       "      <td></td>\n",
       "      <td>nud</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('viidanud', [{'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'A'}, {'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}, {'normalized_text': 'viidanud', 'lemma': 'viitama', 'root': 'viita', 'root_tokens': ['viita'], 'ending': 'nud', 'clitic': '', 'form': 'nud', 'partofspeech': 'V'}])])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example text\n",
    "from estnltk import Text\n",
    "from estnltk.taggers import VabamorfTagger\n",
    "t=Text('viidanud')\n",
    "# Switch off applying reorderer by default\n",
    "t.layer_resolver.update( VabamorfTagger(use_reorderer=False) )\n",
    "\n",
    "# Add morph without reorderer\n",
    "t.tag_layer('morph_analysis')\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>morph_analysis</td>\n",
       "      <td>normalized_text, lemma, root, root_tokens, ending, clitic, form, partofspeech</td>\n",
       "      <td>words</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>normalized_text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>root</th>\n",
       "      <th>root_tokens</th>\n",
       "      <th>ending</th>\n",
       "      <th>clitic</th>\n",
       "      <th>form</th>\n",
       "      <th>partofspeech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viitama</td>\n",
       "      <td>viita</td>\n",
       "      <td>['viita']</td>\n",
       "      <td>nud</td>\n",
       "      <td></td>\n",
       "      <td>nud</td>\n",
       "      <td>V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>sg n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td></td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viidanud</td>\n",
       "      <td>viida=nud</td>\n",
       "      <td>['viidanud']</td>\n",
       "      <td>d</td>\n",
       "      <td></td>\n",
       "      <td>pl n</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='morph_analysis', attributes=('normalized_text', 'lemma', 'root', 'root_tokens', 'ending', 'clitic', 'form', 'partofspeech'), spans=SL[Span('viidanud', [{'normalized_text': 'viidanud', 'lemma': 'viitama', 'root': 'viita', 'root_tokens': ['viita'], 'ending': 'nud', 'clitic': '', 'form': 'nud', 'partofspeech': 'V'}, {'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': '0', 'clitic': '', 'form': '', 'partofspeech': 'A'}, {'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': '0', 'clitic': '', 'form': 'sg n', 'partofspeech': 'A'}, {'normalized_text': 'viidanud', 'lemma': 'viidanud', 'root': 'viida=nud', 'root_tokens': ['viidanud'], 'ending': 'd', 'clitic': '', 'form': 'pl n', 'partofspeech': 'A'}])])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try to ordering\n",
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file=None, \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                          form_freq_csv_file=None )\n",
    "morph_reorderer.retag( t )\n",
    "\n",
    "# Output ambiguities\n",
    "t.morph_analysis[lambda x : len(x.annotations) > 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training data: train || eval data: test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3050 / 4139 (73.69%)\n",
      "   -- correct analysis not first:  937 / 4139 (22.64%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3050 / 4139 (73.69%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_amb.csv',\n",
    "                                          form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3050 / 4139 (73.69%)\n",
      "   -- correct analysis not first:  937 / 4139 (22.64%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3050 / 4139 (73.69%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                          form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3041 / 4139 (73.47%)\n",
      "   -- correct analysis not first:  946 / 4139 (22.86%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3041 / 4139 (73.47%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file = 'et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_amb.csv',\n",
    "                                          form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3041 / 4139 (73.47%)\n",
      "   -- correct analysis not first:  946 / 4139 (22.86%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3041 / 4139 (73.47%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file = 'et_edt-ud-train_sorted_analyses_cut_5.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                          form_freq_csv_file=None )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results I : used only word-to-reorderings and postag_freq lexicons\n",
    "\n",
    "                 used lexicons:                                    eval: test data\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.60%)\n",
    "      (baseline)\n",
    "      ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.91%) \n",
    "     'et_edt-ud-train_cat_postag_freq_amb.csv'\n",
    "      ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.91%) (+)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_cut_5.csv'                 (51.10%) ==> (73.69%)\n",
    "     'et_edt-ud-train_cat_postag_freq_amb.csv'\n",
    "      ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_cut_5.csv'                 (51.10%) ==> (73.69%)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "      ------------------------------------------------------------------------------------\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3042 / 4139 (73.50%)\n",
      "   -- correct analysis not first:  945 / 4139 (22.83%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3042 / 4139 (73.50%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_amb.csv',\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_amb.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2986 / 4139 (72.14%)\n",
      "   -- correct analysis not first:  1001 / 4139 (24.18%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 2986 / 4139 (72.14%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_all.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2986 / 4139 (72.14%)\n",
      "   -- correct analysis not first:  1001 / 4139 (24.18%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 2986 / 4139 (72.14%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_amb.csv',\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_all.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      3042 / 4139 (73.50%)\n",
      "   -- correct analysis not first:  945 / 4139 (22.83%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 3042 / 4139 (73.50%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_amb.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2985 / 4139 (72.12%)\n",
      "   -- correct analysis not first:  1002 / 4139 (24.21%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 2985 / 4139 (72.12%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file=None,\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_all.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 6 texts loaded for evaluation. \n",
      "\n",
      " Evaluation #1: Ambiguous analyses appear in their default ordering \n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2099 / 4139 (50.71%)\n",
      "   -- correct analysis not first:  1888 / 4139 (45.61%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      " Evaluation #2: Ambiguous analyses have been reordered by the morph_reorderer\n",
      "\n",
      "  Ambiguous words total:           4139\n",
      "   -- correct analysis first:      2984 / 4139 (72.09%)\n",
      "   -- correct analysis not first:  1003 / 4139 (24.23%)\n",
      "   -- correct analysis not found:  204 / 4139 (4.93%)\n",
      "\n",
      "\n",
      " Summary: correct analysis first:  2099 / 4139 (50.71%) ==> 2984 / 4139 (72.09%)\n"
     ]
    }
   ],
   "source": [
    "morph_reorderer = MorphAnalysisReorderer( reorderings_csv_file='et_edt-ud-train_sorted_analyses_full.csv', \n",
    "                                          postag_freq_csv_file=None,\n",
    "                                          form_freq_csv_file='et_edt-ud-train_cat_form_freq_amb.csv' )\n",
    "\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "evaluate_reorderer( morph_reorderer, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'dev'], show_fnames=False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results II : used word-to-reorderings, postag_freq and form_freq lexicons \n",
    "\n",
    "                 used lexicons:                                    eval: test data\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.60%)\n",
    "     None\n",
    "     None\n",
    "      (baseline 1)\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.91%)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "     None\n",
    "      (baseline 2)\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (72.37%) (--)\n",
    "     None\n",
    "     'et_edt-ud-train_cat_form_freq_all.csv'\n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (72.35%) (--)\n",
    "     None\n",
    "     'et_edt-ud-train_cat_form_freq_amb.csv' \n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.74%) (-)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "     'et_edt-ud-train_cat_form_freq_amb.csv'      \n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (72.40%) (--)\n",
    "     'et_edt-ud-train_cat_postag_freq_amb.csv'\n",
    "     'et_edt-ud-train_cat_form_freq_all.csv'      \n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (72.40%) (--)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "     'et_edt-ud-train_cat_form_freq_all.csv'  \n",
    "     ------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.74%) (-)\n",
    "     'et_edt-ud-train_cat_postag_freq_amb.csv'\n",
    "     'et_edt-ud-train_cat_form_freq_amb.csv'  \n",
    "      ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "                 used lexicons:                                    eval: test data\n",
    "\n",
    "     ---------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.60%)\n",
    "     None\n",
    "     None\n",
    "      (baseline)\n",
    "     ---------------------------------------------------------------------------------------\n",
    "     'et_edt-ud-train_sorted_analyses_full.csv'                  (51.10%) ==> (73.91%) (+)\n",
    "     'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "     None\n",
    "      (best model 1)\n",
    "     ---------------------------------------------------------------------------------------\n",
    "       'et_edt-ud-train_sorted_analyses_full.csv'                (51.10%) ==> (73.74%) (-)\n",
    "       'et_edt-ud-train_cat_postag_freq_all.csv'\n",
    "       'et_edt-ud-train_cat_form_freq_amb.csv'  \n",
    "      (best model 2)\n",
    "     ---------------------------------------------------------------------------------------\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting morph_analysis_reorderer's diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading evaluation texts (UD_CORPUS)...\n",
      " Total 9 texts loaded for evaluation. \n",
      "\n",
      "Showing differences for all words (including reocurring ones).\n",
      "lükatud\n",
      "    [('lükatud', 'A', ''), ('lükatud', 'A', 'sg n'), ('lükatud', 'A', 'pl n'), ('lükkama', 'V', 'tud')]\n",
      "    --> [('lükkama', 'V', 'tud'), ('lükatud', 'A', ''), ('lükatud', 'A', 'sg n'), ('lükatud', 'A', 'pl n')] (-)\n",
      "lükatud\n",
      "    [('lükatud', 'A', ''), ('lükatud', 'A', 'sg n'), ('lükatud', 'A', 'pl n'), ('lükkama', 'V', 'tud')]\n",
      "    --> [('lükkama', 'V', 'tud'), ('lükatud', 'A', ''), ('lükatud', 'A', 'sg n'), ('lükatud', 'A', 'pl n')] (+)\n",
      "vaevelnud\n",
      "    [('vaevelnud', 'A', ''), ('vaevelnud', 'A', 'sg n'), ('vaevelnud', 'A', 'pl n'), ('vaevlema', 'V', 'nud')]\n",
      "    --> [('vaevlema', 'V', 'nud'), ('vaevelnud', 'A', ''), ('vaevelnud', 'A', 'sg n'), ('vaevelnud', 'A', 'pl n')] (+)\n",
      "torganud\n",
      "    [('torganud', 'A', ''), ('torganud', 'A', 'sg n'), ('torganud', 'A', 'pl n'), ('torkama', 'V', 'nud')]\n",
      "    --> [('torkama', 'V', 'nud'), ('torganud', 'A', ''), ('torganud', 'A', 'sg n'), ('torganud', 'A', 'pl n')] (+)\n",
      "meigitud\n",
      "    [('meigitud', 'A', ''), ('meigitud', 'A', 'sg n'), ('meigitud', 'A', 'pl n'), ('meikima', 'V', 'tud')]\n",
      "    --> [('meikima', 'V', 'tud'), ('meigitud', 'A', ''), ('meigitud', 'A', 'sg n'), ('meigitud', 'A', 'pl n')] (-)\n",
      "kohmetud\n",
      "    [('kohmetu', 'A', 'pl n'), ('kohmetuma', 'V', 'd')]\n",
      "    --> [('kohmetuma', 'V', 'd'), ('kohmetu', 'A', 'pl n')] (-)\n",
      "\n",
      " Total differences:   6\n",
      " Total improvements:  3 / 6 (50.00%)\n"
     ]
    }
   ],
   "source": [
    "from eval_utils import diff_reorderer\n",
    "\n",
    "morph_reorderer1 = MorphAnalysisReorderer( postag_freq_csv_file=None,\n",
    "                                           form_freq_csv_file=None )\n",
    "\n",
    "morph_reorderer2 = MorphAnalysisReorderer( postag_freq_csv_file='et_edt-ud-train_cat_postag_freq_all.csv',\n",
    "                                           form_freq_csv_file=None )\n",
    "\n",
    "import os, os.path\n",
    "input_dir = 'UD_converted'\n",
    "assert os.path.isdir( input_dir )\n",
    "\n",
    "from eval_utils import evaluate_reorderer, GoldStandard\n",
    "\n",
    "diff_reorderer( morph_reorderer1, morph_reorderer2, input_dir, 'ud_morph_reduced', gold_morph_type=GoldStandard.UD_CORPUS, \\\n",
    "                    exclude_strs=['train', 'test'], debug_take_first=False, show_fnames=False, show_all_diffs=True  )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
