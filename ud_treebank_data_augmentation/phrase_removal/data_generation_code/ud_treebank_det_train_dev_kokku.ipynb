{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2549937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539916a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3d3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from estnltk.converters.conll.conll_importer import conll_to_text\n",
    "from estnltk_core.layer_operations import split_by_sentences\n",
    "from estnltk_patches.phrase_extractor import PhraseExtractor\n",
    "from estnltk_patches.consistency_decorator import ConsistencyDecorator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff6df9",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbff3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "root1 = r\"UDpuupank/UD2_11_udreposse/Train\"\n",
    "root2 = r\"UDpuupank/UD2_11_udreposse/Dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac19c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = []\n",
    "for path, subdirs, filess in os.walk(root1):\n",
    "    files1 = filess \n",
    "\n",
    "files2 = []\n",
    "for path, subdirs, filess2 in os.walk(root2):\n",
    "    files2 = filess2 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18b11c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = \"det_phrases\"\n",
    "model_path = r\".../lib/python3.9/site-packages/estnltk_neural/taggers/syntax/stanza_tagger/stanza_resources/\"\n",
    "deprel = \"det\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b89c579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "decorator = ConsistencyDecorator(\"sentences\", model_path, \"temp_phrases\", \"stanza_syntax\", \"sentences\")\n",
    "\n",
    "\n",
    "phrase_tagger = PhraseExtractor(deprel=deprel, decorator=decorator, input_type=\"stanza_syntax\", \n",
    "                                syntax_layer=\"stanza_syntax\", output_layer=output_layer, morph_layer=\"words\",\n",
    "                               output_attributes = ['syntax_conservation_score', \"unlabelled_attachment_score\", \"label_accuracy\",'root_id', 'root']\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d21d00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_tag_texts(files, root):\n",
    "\n",
    "    texts = []\n",
    "    file_sent_info = []\n",
    "\n",
    "    for file in tqdm(files):\n",
    "\n",
    "        input_file = os.path.join(root, file)\n",
    "        text_obj = conll_to_text( input_file, syntax_layer='stanza_syntax' )\n",
    "        texts2 = split_by_sentences(text=text_obj,\n",
    "                                   layers_to_keep=list(text_obj.layers),\n",
    "                                   trim_overlapping=True\n",
    "                                   )\n",
    "        for txt in texts2:\n",
    "            phrase_tagger.tag(txt)\n",
    "        \n",
    "        texts3 = []\n",
    "        for text in texts2:\n",
    "            if output_layer in text.layers and len(text[output_layer])>0:\n",
    "                texts3.append(text)\n",
    "        \n",
    "        for txt in texts3:\n",
    "            for i in range(len(txt[output_layer])):\n",
    "                obj = txt[output_layer][i]\n",
    "                removed = \" \".join(obj.text)\n",
    "                cons = str(obj.syntax_conservation_score)\n",
    "                ual = str(obj.unlabelled_attachment_score)\n",
    "                la = str(obj.label_accuracy)\n",
    "                textdata = \"\\\\\".join([file, txt.text, removed, cons, ual, la])\n",
    "                #print(textdata)\n",
    "                file_sent_info.append(textdata)\n",
    "\n",
    "        texts += texts3\n",
    "        \n",
    "    return texts, file_sent_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "edb57354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 60/60 [28:53<00:00, 28.90s/it]\n"
     ]
    }
   ],
   "source": [
    "files1_txt, fileinfo1 = split_and_tag_texts(files1, root1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e6f39a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4668 5389\n"
     ]
    }
   ],
   "source": [
    "print(len(files1_txt), len(fileinfo1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bccf3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 9/9 [04:20<00:00, 28.89s/it]\n"
     ]
    }
   ],
   "source": [
    "files2_txt, fileinfo2 = split_and_tag_texts(files2, root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84af3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "577 672\n"
     ]
    }
   ],
   "source": [
    "print(len(files2_txt), len(fileinfo2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d39b0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinfo = fileinfo1 + fileinfo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58924a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ls_puupank_{deprel}_export_big_v1_fileinfo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"file\\\\text\\\\removed\\\\conservation_score\\\\ual\\\\la\\n\")\n",
    "    f.write('\\n'.join('%s' % x for x in fileinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9b0c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "698b4fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>det_phrases</td>\n",
       "      <td>syntax_conservation_score, unlabelled_attachment_score, label_accuracy, root_id, root</td>\n",
       "      <td>None</td>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>syntax_conservation_score</th>\n",
       "      <th>unlabelled_attachment_score</th>\n",
       "      <th>label_accuracy</th>\n",
       "      <th>root_id</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['üks']</td>\n",
       "      <td>56.2</td>\n",
       "      <td>62.5</td>\n",
       "      <td>68.8</td>\n",
       "      <td>9</td>\n",
       "      <td>Span('üks', [{'id': 9, 'lemma': 'üks', 'upostag': 'DET', 'xpostag': 'P', 'feats' ..., type: &lt;class 'estnltk_core.layer.span.Span'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='det_phrases', attributes=('syntax_conservation_score', 'unlabelled_attachment_score', 'label_accuracy', 'root_id', 'root'), spans=SL[EnvelopingSpan(['üks'], [{'syntax_conservation_score': 56.2, 'unlabelled_attachment_score': 62.5, 'label_accuracy': 68.8, 'root_id': 9, 'root': <class 'estnltk_core.layer.span.Span'>}])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files2_txt[0].det_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2703c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = files1_txt + files2_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a4c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73d1dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5245"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e6409",
   "metadata": {},
   "source": [
    "## Files for label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d5df837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collection_to_ls import collection_to_labelstudio, conf_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80b58922",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = f\"ls_puupank_{deprel}_export_big_v1.json\"\n",
    "collection_to_labelstudio(texts, deprel, regular_layers=[output_layer],filename=res_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "18b50fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"ls_puupank_{deprel}_export_big_v1_conf.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(conf_gen(deprel, classes=[output_layer]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc9949f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
