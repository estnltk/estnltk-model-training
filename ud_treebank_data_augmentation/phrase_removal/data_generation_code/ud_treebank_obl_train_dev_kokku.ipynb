{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2549937d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "539916a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab3d3d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from estnltk.converters.conll.conll_importer import conll_to_text\n",
    "from estnltk_core.layer_operations import split_by_sentences\n",
    "from estnltk_patches.phrase_extractor import PhraseExtractor\n",
    "from estnltk_patches.consistency_decorator import ConsistencyDecorator\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ff6df9",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bbff3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "root1 = r\"UDpuupank/UD2_11_udreposse/Train\"\n",
    "root2 = r\"UDpuupank/UD2_11_udreposse/Dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ac19c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "files1 = []\n",
    "for path, subdirs, filess in os.walk(root1):\n",
    "    files1 = filess \n",
    "\n",
    "files2 = []\n",
    "for path, subdirs, filess2 in os.walk(root2):\n",
    "    files2 = filess2 \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89c579f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = \"obl_phrases\"\n",
    "model_path = r\".../lib/python3.9/site-packages/estnltk_neural/taggers/syntax/stanza_tagger/stanza_resources/\"\n",
    "\n",
    "decorator = ConsistencyDecorator(\"sentences\", model_path, \"obl_phrases2\", \"stanza_syntax\", \"sentences\")\n",
    "\n",
    "\n",
    "phrase_tagger = PhraseExtractor(deprel=\"obl\", decorator=decorator, input_type=\"stanza_syntax\", \n",
    "                                syntax_layer=\"stanza_syntax\", output_layer=output_layer, morph_layer=\"words\",\n",
    "                               output_attributes = ['syntax_conservation_score', \"unlabelled_attachment_score\", \"label_accuracy\",'root_id', 'root']\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21d00c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_tag_texts(files, root):\n",
    "\n",
    "    texts = []\n",
    "    file_sent_info = []\n",
    "\n",
    "    for file in tqdm(files):\n",
    "\n",
    "        input_file = os.path.join(root, file)\n",
    "        text_obj = conll_to_text( input_file, syntax_layer='stanza_syntax' )\n",
    "        texts2 = split_by_sentences(text=text_obj,\n",
    "                                   layers_to_keep=list(text_obj.layers),\n",
    "                                   trim_overlapping=True\n",
    "                                   )\n",
    "        for txt in texts2:\n",
    "            phrase_tagger.tag(txt)\n",
    "        \n",
    "        texts3 = []\n",
    "        for text in texts2:\n",
    "            if output_layer in text.layers and len(text[output_layer])>0:\n",
    "                texts3.append(text)\n",
    "        \n",
    "        for txt in texts3:\n",
    "            for i in range(len(txt[output_layer])):\n",
    "                obj = txt[output_layer][i]\n",
    "                removed = \" \".join(obj.text)\n",
    "                cons = str(obj.syntax_conservation_score)\n",
    "                ual = str(obj.unlabelled_attachment_score)\n",
    "                la = str(obj.label_accuracy)\n",
    "                textdata = \"\\\\\".join([file, txt.text, removed, cons, ual, la])\n",
    "                #print(textdata)\n",
    "                file_sent_info.append(textdata)\n",
    "\n",
    "        texts += texts3\n",
    "        \n",
    "    return texts, file_sent_info\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edb57354",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 60/60 [2:01:27<00:00, 121.46s/it]\n"
     ]
    }
   ],
   "source": [
    "files1_txt, fileinfo1 = split_and_tag_texts(files1, root1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6f39a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16588 31308\n"
     ]
    }
   ],
   "source": [
    "print(len(files1_txt), len(fileinfo1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bccf3776",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 9/9 [17:10<00:00, 114.49s/it]\n"
     ]
    }
   ],
   "source": [
    "files2_txt, fileinfo2 = split_and_tag_texts(files2, root2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84af3348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2114 3915\n"
     ]
    }
   ],
   "source": [
    "print(len(files2_txt), len(fileinfo2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d39b0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileinfo = fileinfo1 + fileinfo2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58924a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ls_puupank_obl_export_big_v2_fileinfo.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"file\\\\text\\\\removed\\\\conservation_score\\\\ual\\\\la\\n\")\n",
    "    f.write('\\n'.join('%s' % x for x in fileinfo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c9b0c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2703c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = files1_txt + files2_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1a4c5fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "73d1dca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18702"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a670cf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts1 = texts[:10000]\n",
    "texts2 = texts[10000:]\n",
    "#texts3 = texts[20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "232c259d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h4>Layer</h4>\n",
       "\n",
       "\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>layer name</th>\n",
       "      <th>attributes</th>\n",
       "      <th>parent</th>\n",
       "      <th>enveloping</th>\n",
       "      <th>ambiguous</th>\n",
       "      <th>span count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>obl_phrases</td>\n",
       "      <td>syntax_conservation_score, unlabelled_attachment_score, label_accuracy, root_id, root</td>\n",
       "      <td>None</td>\n",
       "      <td>stanza_syntax</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>text</th>\n",
       "      <th>syntax_conservation_score</th>\n",
       "      <th>unlabelled_attachment_score</th>\n",
       "      <th>label_accuracy</th>\n",
       "      <th>root_id</th>\n",
       "      <th>root</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>['endast']</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>4</td>\n",
       "      <td>Span('endast', [{'id': 4, 'lemma': 'ise', 'upostag': 'PRON', 'xpostag': 'P', 'fe ..., type: &lt;class 'estnltk_core.layer.span.Span'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>['järsu', 'liigutusega']</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6</td>\n",
       "      <td>Span('liigutusega', [{'id': 6, 'lemma': 'liigutus', 'upostag': 'NOUN', 'xpostag' ..., type: &lt;class 'estnltk_core.layer.span.Span'&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "Layer(name='obl_phrases', attributes=('syntax_conservation_score', 'unlabelled_attachment_score', 'label_accuracy', 'root_id', 'root'), spans=SL[EnvelopingSpan(['endast'], [{'syntax_conservation_score': 100.0, 'unlabelled_attachment_score': 100.0, 'label_accuracy': 100.0, 'root_id': 4, 'root': <class 'estnltk_core.layer.span.Span'>}]),\n",
       "EnvelopingSpan(['järsu', 'liigutusega'], [{'syntax_conservation_score': 100.0, 'unlabelled_attachment_score': 100.0, 'label_accuracy': 100.0, 'root_id': 6, 'root': <class 'estnltk_core.layer.span.Span'>}])])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts1[1].obl_phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3e6409",
   "metadata": {},
   "source": [
    "## Files for label studio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35173b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "deprel = \"obl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d5df837",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collection_to_ls import collection_to_labelstudio, conf_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "80b58922",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_path = \"ls_puupank_obl_export_big_v2_1.json\"\n",
    "collection_to_labelstudio(texts1, deprel, regular_layers=[\"obl_phrases\"],filename=res_path)\n",
    "\n",
    "res_path = \"ls_puupank_obl_export_big_v2_2.json\"\n",
    "collection_to_labelstudio(texts2, deprel, regular_layers=[\"obl_phrases\"],filename=res_path)\n",
    "\n",
    "#res_path = \"ls_puupank_obl_export_big_v2_3.json\"\n",
    "#collection_to_labelstudio(texts3, deprel, regular_layers=[\"obl_phrases\"],filename=res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18b50fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ls_puupank_obl_export_big_v2_conf.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(conf_gen(deprel, classes=[\"obl_phrases\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400756e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
