

## text_tokenizer.py

Creates a vocabulary (if not provided) and creates tokenizations of texts that can be used for training

