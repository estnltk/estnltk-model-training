{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alus - sihitis kollokatsioonid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vajalikud teegid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import estnltk\n",
    "from estnltk.storage.postgres import PostgresStorage\n",
    "\n",
    "import networkx as nx\n",
    "import sqlite3\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abifunktsioonid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphFunctions:\n",
    "\n",
    "    # kahe listi ühisosa \n",
    "    def intersection(a, b):\n",
    "        return list(set(a).intersection(b))\n",
    "\n",
    "    # tipu leidmine atribuudi väärtuse järgi\n",
    "    def get_nodes_by_attributes(G,  attrname, attrvalue ):\n",
    "        nodes = defaultdict(list)\n",
    "        {nodes[v].append(k) for k, v in nx.get_node_attributes(G,attrname).items()}\n",
    "        if attrvalue in nodes:\n",
    "            return dict(nodes)[attrvalue]\n",
    "        return []\n",
    "\n",
    "    # graafi joonistamine \n",
    "    # tipp - lemma\n",
    "    # serv - deprel\n",
    "    def drawGraph(G):\n",
    "        pos = graphviz_layout(G, prog='dot')\n",
    "        labels = nx.get_node_attributes(G, 'lemma')\n",
    "        nx.draw(G, pos, cmap = plt.get_cmap('jet'),labels=labels, with_labels=True)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'deprel')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baasi  (sqlite3)  ettevalmistamine täitmiseks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luuakse tabelid:\n",
    "* collections_processed - salvestatakse viimane salvestatud collection Id\n",
    "* {TABLENAME} - tabel kollokatsioonidega\n",
    " * lemma1 text\n",
    " * pos1 text\n",
    " * lemma2 text\n",
    " * pos2 text\n",
    " * total integer\n",
    " * example1 text\n",
    " * example2 text\n",
    " * example3 text\n",
    "\n",
    "Luuakse indeksid:\n",
    "* collections_processed_uniq\n",
    "* {TABLENAME}_col1_col2_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepCollDb():\n",
    "    global TABLENAME, cursor, conn\n",
    "\n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS collections_processed\n",
    "                      (tablename text, lastcollection integer);\n",
    "                      \"\"\")\n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS collections_processed_uniq ON collections_processed(tablename);\n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {TABLENAME}\n",
    "                      (lemma1 text, pos1 text, lemma2 text, pos2 text, total integer, example1 text, example2 text, example3 text);\n",
    "                      \"\"\")\n",
    "\n",
    "    INDEXNAME = f'{TABLENAME}_col1_col2_unique'\n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}\n",
    "        ON {TABLENAME}(lemma1, pos1, lemma2, pos2);\n",
    "        \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuse salvestamine baasi (sqlite3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCollToDb(collocations, examples, lastcollection):\n",
    "    \n",
    "    global TABLENAME, cursor, conn\n",
    "    sqlColls = []\n",
    "\n",
    "    for key in collocations.keys():\n",
    "        example1 = None\n",
    "        example2 = None\n",
    "        example3 = None\n",
    "\n",
    "        if len(examples[key])>0:\n",
    "            example1 = examples[key][0]\n",
    "        if len(examples[key])>1:\n",
    "            example2 = examples[key][1]\n",
    "        if len(examples[key])>2:\n",
    "            example3 = examples[key][2]\n",
    "\n",
    "        sqlColls.append( (key[0], key[2], key[1],  key[3], collocations[key], example1, example2, example3 , collocations[key], example1, example2,example3,) )\n",
    "\n",
    "    cursor.executemany(f\"\"\"\n",
    "        INSERT INTO {TABLENAME} VALUES (?,?,?,?,?,?,?,?)\n",
    "        ON CONFLICT(lemma1, pos1, lemma2, pos2)\n",
    "        DO UPDATE SET total=total+?\n",
    "            ,  example1= ?\n",
    "            ,  example2= ?\n",
    "            ,  example3= ?\n",
    "            ;\"\"\", sqlColls)\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO collections_processed VALUES (?,?)\n",
    "        ON CONFLICT(tablename) DO UPDATE SET lastcollection=?;\"\"\", (TABLENAME, lastcollection, lastcollection,) )\n",
    "    \n",
    "    conn.commit()\n",
    "    eprint(f'andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - {lastcollection}' )\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alus - sihitis sõltuvuste leidmine "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alus - sihitis seosed\n",
    "1. Leitakse kõik sõnaliigiga V tipud\n",
    "2. Leitakse kõik tipud deprel = **nsubj** ja deprel = **csubj**\n",
    "3. Leitakse kõik tipud deprel = **nsubj:cop** ja deprel = **csubj:cop**\n",
    "\n",
    "Alus-sihitis kollokaatideks loetakse:\n",
    "* tipp1, mille deprel on **nsubj** või **csubj** ja tema vahetu vanem (parent), tipp2 sõnaliigiga pos = **V**\n",
    "* tipp1, mille deprel on **nsubj:cop** või **csubj:cop** ja tipp2, millel on tipp1-ga ühine vanem ja mille sõnaliik pos = **V** ja deprel = **cop** \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_verb_subject(G, collocations, examples, sentence):\n",
    "\n",
    "    # lyhim tee tippude vahel\n",
    "    path = nx.all_pairs_shortest_path_length(G)\n",
    "    path_reversed = nx.all_pairs_shortest_path_length(G.reverse())\n",
    "\n",
    "    # kauguste maatriksid\n",
    "    dpath = {x[0]:x[1] for x in path}\n",
    "    dpath_reversed = {x[0]:x[1] for x in path}\n",
    "\n",
    "    # eraldame tipud vajalike parameetritega\n",
    "    verbnodes = graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'V')\n",
    "\n",
    "    # need peavad vahetult seotud olema\n",
    "    subjnodes = graphFunctions.get_nodes_by_attributes(G, attrname = 'deprel', attrvalue = 'nsubj') + graphFunctions.get_nodes_by_attributes(G, attrname = 'deprel', attrvalue = 'csubj')\n",
    "\n",
    "    #nendega peab olema keerulisem seos\n",
    "    subjcopnodes = graphFunctions.get_nodes_by_attributes(G, attrname = 'deprel', attrvalue = 'nsubj:cop') + graphFunctions.get_nodes_by_attributes(G, attrname = 'deprel', attrvalue = 'csubj:cop')\n",
    "\n",
    "    #liigume tegusõnade kaupa\n",
    "    for verb in verbnodes:\n",
    "        for subj in subjnodes:\n",
    "            if subj in dpath[verb] and dpath[verb][subj]==1:\n",
    "                #print (verb, subj)\n",
    "                key = ( G.nodes[subj]['lemma'], G.nodes[verb]['lemma'], G.nodes[subj]['pos'],  G.nodes[verb]['pos'] , )\n",
    "                #print (key)\n",
    "                if not key in collocations:\n",
    "                    collocations[key] = 0\n",
    "                if not key in examples:\n",
    "                    examples[key] = []\n",
    "                collocations[key] += 1\n",
    "                examples[key].append(sentence)\n",
    "                if len(examples[key]) > 3:\n",
    "                    del(examples[key][random.randint(0, 2)])\n",
    "\n",
    "        # siin otsime kaugemal seotud subjecte\n",
    "        # peab olema V cop tipuga ühine vanem\n",
    "        #print (G.nodes[verb])\n",
    "        if G.nodes[verb]['deprel'] == 'cop':\n",
    "            #neighbors\n",
    "            #predecessors\n",
    "            #should be always one parent\n",
    "            #tegusõna parent\n",
    "            parents = [parent for parent in G.predecessors(verb)]\n",
    "            if len(parents)> 1:\n",
    "                eprint ('Mingi jama puu struktuuriga - tipul on rohkem kui üks vanem')\n",
    "                graphFunctions.drawGraph(G)\n",
    "                exit()\n",
    "            parent = parents[0]\n",
    "            siblings = [sibling for sibling in G.successors(parent)]\n",
    "            fitted_nodes = graphFunctions.intersection(subjcopnodes, siblings)\n",
    "            for subjcop in fitted_nodes:\n",
    "                key = ( G.nodes[subjcop]['lemma'], G.nodes[verb]['lemma'], G.nodes[subjcop]['pos'],  G.nodes[verb]['pos'] , )\n",
    "                if not key in collocations:\n",
    "                    collocations[key] = 0\n",
    "                if not key in examples:\n",
    "                    examples[key] = []\n",
    "                collocations[key] += 1\n",
    "                examples[key].append(sentence)\n",
    "                if len(examples[key]) > 3:\n",
    "                    del(examples[key][random.randint(0, 3)])\n",
    "            #graphFunctions.drawGraph(G);\n",
    "    return (collocations, examples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPlaceholder(tablename):\n",
    "    cursor.execute(f\"\"\"SELECT lastcollection FROM collections_processed WHERE tablename = ?\"\"\", (tablename,) );\n",
    "    lastcollection = cursor.fetchone()\n",
    "\n",
    "    if not lastcollection:\n",
    "        lastcollection = -1\n",
    "    else:\n",
    "        #andmete kogumine jäi pooleli ning jätkatakse samasse faili kirjutamist\n",
    "        lastcollection = lastcollection[0]\n",
    "    return lastcollection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muutujad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Korpuse TSV fail**\n",
    "\n",
    "Lähte TSV-faili ja DB tabeli nimi, kuhu tulemus salvestatakse (TSV genereerimise kood on failis **collect_texts_db_tsv.ipynb**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = 'koondkorpus_base_subset_of_5000_v2' # 'koondkorpus_base_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollokatsiooni tüüp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'subj_verb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabeli nimi andmebaasis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLENAME = f'{TYPE}_{collectionName}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollektsioonide arv**, mille kaupa salvestatakse vahepealne tulemus andmebaasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andmebaasi loomine ja ette valmistamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f\"{TYPE}_collocations.db\") #\n",
    "cursor = conn.cursor()\n",
    "prepCollDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kollokatsioonide alla laadimine ja salvestamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:storage.py:42: connecting to host: 'postgres.keeleressursid.ee', port: '5432', dbname: 'estonian-text-corpora', user: 'zummy'\n",
      "INFO:storage.py:58: schema: 'estonian_text_corpora', temporary: False, role: 'estonian_text_corpora_read'\n"
     ]
    }
   ],
   "source": [
    "storage = PostgresStorage(pgpass_file='~/.pgpass',\n",
    "                          schema='estonian_text_corpora',\n",
    "                          role='estonian_text_corpora_read',\n",
    "                          temporary=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = storage[collectionName]\n",
    "TOTALROWS = len(collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kontrollitakse, mitmenda kollektsiooni juurde skript eelmine kord jäi, juhul kui skripti töö katkes ootamatult. **Nullist alustamiseks tuleb kustutada skripti loodud *{TYPE}_collocations.db* fail.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5001 out of 5000 collections to download\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65f62d87b60941dbae1f69c5e976ef84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 999\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 1999\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 2999\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 3999\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 4999\n"
     ]
    }
   ],
   "source": [
    "lastcollection = getPlaceholder(TABLENAME)\n",
    "\n",
    "#mitu kollektsiooni jäi alla tõmbamata\n",
    "unprocessed = TOTALROWS - lastcollection - 1\n",
    "\n",
    "eprint (f'{unprocessed} out of {TOTALROWS} collections to download')\n",
    "\n",
    "###\n",
    "collocations = {}\n",
    "examples = {}\n",
    "iterations = 0\n",
    "unsaved = 0\n",
    "\n",
    "word_id = 0\n",
    "\n",
    "for (colId, text) in collection.select (progressbar='notebook', layers=['v166_sentences', 'v168_stanza_ensemble_syntax'], return_index=True ).tail(unprocessed):\n",
    "    sentences_start = [span.start for span in text.v166_sentences]\n",
    "    sentences_end = [span.end for span in text.v166_sentences]\n",
    "    \n",
    "    iterations +=1\n",
    "    unsaved = 1\n",
    "    \n",
    "    for span in text.v168_stanza_ensemble_syntax:\n",
    "        \n",
    "        word_id +=1\n",
    "        \n",
    "        #lause algus\n",
    "        if span.start in sentences_start:\n",
    "            current_sentence = []\n",
    "            word_id +=1\n",
    "            G = nx.DiGraph()\n",
    "        \n",
    "        G.add_node(word_id, id=span.id, lemma=span.lemma, pos=span.upostag, deprel=span.deprel)\n",
    "        G.add_edge(word_id - span.id + span.head, word_id, deprel = span.deprel)\n",
    "        \n",
    "        current_sentence.append(span)\n",
    "        \n",
    "        #lause lõpp\n",
    "        if span.end in sentences_end:\n",
    "            current_sentence_text = ' '.join([s.text for s in current_sentence])\n",
    "            (collocations, examples) = extract_verb_subject(G, collocations, examples, current_sentence_text)\n",
    "            unsaved = 1\n",
    "            continue\n",
    "    \n",
    "    if not iterations%BATCHSIZE:\n",
    "        saveCollToDb(collocations, examples, colId)\n",
    "        collocations = {}\n",
    "        unsaved = 0\n",
    "\n",
    "if unsaved: saveCollToDb(collocations, examples, colId)\n",
    "eprint (\"Done.\")\n",
    "\n",
    "##########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andmebaasi indeksite lisamine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehakse kõige viimasena, et andmete sisestamine andmebaasi oleks kiirem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexesQ = [\n",
    "    f'CREATE INDEX IF NOT EXISTS \"lemma1\" ON \"{TABLENAME}\" (\"lemma1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"lemma2\" ON \"{TABLENAME}\" (\"lemma2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos1\" ON \"{TABLENAME}\" (\"pos1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos2\" ON \"{TABLENAME}\" (\"pos2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"total\" ON \"{TABLENAME}\" (\"total\" DESC);']\n",
    "\n",
    "for q in indexesQ: cursor.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"SELECT count(*) FROM {TABLENAME}\")\n",
    "all_collocations = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(82701,)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_collocations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
