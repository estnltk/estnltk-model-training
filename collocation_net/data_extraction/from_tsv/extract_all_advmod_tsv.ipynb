{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kõik  deprel=\"amod\" vahetult seotud  tipud  (korpuse tsv faili alusel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vajalikud teegid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#import etnltk\n",
    "#from estnltk.storage.postgres import PostgresStorage\n",
    "\n",
    "import networkx as nx\n",
    "import sqlite3\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abifunktsioonid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphFunctions:\n",
    "\n",
    "    # kahe listi ühisosa \n",
    "    def intersection(a, b):\n",
    "        return list(set(a).intersection(b))\n",
    "\n",
    "    # tipu leidmine atribuudi väärtuse järgi\n",
    "    def get_nodes_by_attributes(G,  attrname, attrvalue ):\n",
    "        nodes = defaultdict(list)\n",
    "        {nodes[v].append(k) for k, v in nx.get_node_attributes(G,attrname).items()}\n",
    "        if attrvalue in nodes:\n",
    "            return dict(nodes)[attrvalue]\n",
    "        return []\n",
    "\n",
    "    # graafi joonistamine \n",
    "    # tipp - lemma\n",
    "    # serv - deprel\n",
    "    def drawGraph(G):\n",
    "        pos = graphviz_layout(G, prog='dot')\n",
    "        labels = nx.get_node_attributes(G, 'lemma')\n",
    "        nx.draw(G, pos, cmap = plt.get_cmap('jet'),labels=labels, with_labels=True)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'deprel')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baasi  (sqlite3)  ettevalmistamine täitmiseks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luuakse tabelid:\n",
    "* collections_processed - salvestatakse viimane salvestatud collection Id\n",
    "* {TABLENAME} - tabel kollokatsioonidega\n",
    " * lemma1 text\n",
    " * pos1 text\n",
    " * lemma2 text\n",
    " * pos2 text\n",
    " * total integer\n",
    " * example1 text\n",
    " * example2 text\n",
    " * example3 text\n",
    "\n",
    "Luuakse indeksid:\n",
    "* collections_processed_uniq\n",
    "* {TABLENAME}_col1_col2_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepCollDb():\n",
    "    global TABLENAME, cursor, conn\n",
    "\n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS collections_processed\n",
    "                      (tablename text, lastcollection integer);\n",
    "                      \"\"\")\n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS collections_processed_uniq ON collections_processed(tablename);\n",
    "    \"\"\")\n",
    "    \n",
    "    #tsv failist lugemise korral loome tabeli alati nullist\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO collections_processed VALUES (?,?)\n",
    "        ON CONFLICT(tablename) DO UPDATE SET lastcollection=?;\"\"\", (TABLENAME, 0, 0,) )\n",
    "    \n",
    " \n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS {TABLENAME}\n",
    "                      (lemma1 text, pos1 text, lemma2 text, pos2 text, total integer, example1 text, example2 text, example3 text);\n",
    "                      \"\"\")\n",
    "\n",
    "    #tsv failist lugemise korral loome tabeli alati nullist\n",
    "    cursor.execute(f\"\"\"DELETE FROM {TABLENAME};\"\"\")\n",
    "\n",
    "    \n",
    "    INDEXNAME = f'{TABLENAME}_col1_col2_unique'\n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}\n",
    "        ON {TABLENAME}(lemma1, pos1, lemma2, pos2);\n",
    "        \"\"\")\n",
    "    \n",
    "    conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuse salvestamine baasi (sqlite3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCollToDb(collocations, examples, lastcollection):\n",
    "    \n",
    "    global TABLENAME, cursor, conn\n",
    "    sqlColls = []\n",
    "\n",
    "    for key in collocations.keys():\n",
    "        example1 = None\n",
    "        example2 = None\n",
    "        example3 = None\n",
    "\n",
    "        if len(examples[key])>0:\n",
    "            example1 = examples[key][0]\n",
    "        if len(examples[key])>1:\n",
    "            example2 = examples[key][1]\n",
    "        if len(examples[key])>2:\n",
    "            example3 = examples[key][2]\n",
    "\n",
    "        sqlColls.append( (key[0], key[2], key[1],  key[3], collocations[key], example1, example2, example3 , collocations[key], example1, example2,example3,) )\n",
    "\n",
    "    cursor.executemany(f\"\"\"\n",
    "        INSERT INTO {TABLENAME} VALUES (?,?,?,?,?,?,?,?)\n",
    "        ON CONFLICT(lemma1, pos1, lemma2, pos2)\n",
    "        DO UPDATE SET total=total+?\n",
    "            ,  example1= ?\n",
    "            ,  example2= ?\n",
    "            ,  example3= ?\n",
    "            ;\"\"\", sqlColls)\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO collections_processed VALUES (?,?)\n",
    "        ON CONFLICT(tablename) DO UPDATE SET lastcollection=?;\"\"\", (TABLENAME, lastcollection, lastcollection,) )\n",
    "    \n",
    "    conn.commit()\n",
    "    eprint(f'andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - {lastcollection}' )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### advmod - sõltuvuste leidmine \n",
    "\n",
    "* Kõik paarid, mille vahel on deprel = advmod\n",
    "\n",
    "#### Näide 1\n",
    "\n",
    "autor --> eelkõige\n",
    "\n",
    "<img src=\"img/all_advmod_01.png\" width=\"600\" />\n",
    "\n",
    "#### Näide 2\n",
    "\n",
    "palju --> võimalikult\n",
    "\n",
    "müra --> palju\n",
    "\n",
    "<img src=\"img/all_advmod_02.png\" width=\"600\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_advmod(G, collocations, examples, sentence):\n",
    "        # lyhim tee tippude vahel\n",
    "        path = nx.all_pairs_shortest_path_length(G)\n",
    "        path_reversed = nx.all_pairs_shortest_path_length(G.reverse())\n",
    "\n",
    "        # kauguste maatriksid\n",
    "        dpath = {x[0]:x[1] for x in path}\n",
    "        dpath_reversed = {x[0]:x[1] for x in path}\n",
    "\n",
    "        #eprint('eraldame tipud vajalike parameetritega ')\n",
    "        advmod_nodes = graphFunctions.get_nodes_by_attributes(G,  attrname = 'deprel', attrvalue =  'advmod')\n",
    "\n",
    "        for node in advmod_nodes:\n",
    "            parents = [parent for parent in G.predecessors(node)]\n",
    "            if len(parents)>1:\n",
    "                print ('Mingi jama puu struktuuriga - tipul on rohkem kui üks vanem')\n",
    "                synFunctions.drawGraph(G)\n",
    "                exit(1)\n",
    "            parent = parents[0]\n",
    "            #print (G.nodes[parent]['lemma'], '-->', G.nodes[node]['lemma'])\n",
    "            #graphFunctions.drawGraph(G, parent, node);\n",
    "            try:\n",
    "                key = ( G.nodes[parent]['lemma'], G.nodes[node]['lemma'], G.nodes[parent]['pos'],  G.nodes[node]['pos'] , )\n",
    "\n",
    "            except:\n",
    "                print('Mingi jama puu struktuuriga', node, parent)\n",
    "                print (sentence )\n",
    "                print (G.nodes)\n",
    "                print (G.edges)\n",
    "                continue\n",
    "\n",
    "            if not key in collocations:\n",
    "                collocations[key] = 0\n",
    "            if not key in examples:\n",
    "                examples[key] = []\n",
    "            collocations[key] += 1\n",
    "            examples[key].append(sentence)\n",
    "            if len(examples[key]) > 3:\n",
    "                del(examples[key][random.randint(0, 2)])\n",
    "        return (collocations, examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muutujad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Korpuse TSV fail**\n",
    "\n",
    "Lähte TSV-faili ja DB tabeli nimi, kuhu tulemus salvestatakse (TSV genereerimise kood on failis **collect_texts_db_tsv.ipynb**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName = 'koondkorpus_base_subset_of_5000_v2' # 'koondkorpus_base_v2'\n",
    "corporafile = f'{collectionName}.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollokatsiooni tüüp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'ALL_advmod'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabeli nimi andmebaasis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLENAME = f'{TYPE}_{collectionName}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollektsioonide arv**, mille kaupa salvestatakse vahepealne tulemus andmebaasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andmebaasi loomine ja ette valmistamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f\"{TYPE}_collocations.db\") #\n",
    "cursor = conn.cursor()\n",
    "prepCollDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kollokatsioonide leidmine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andmed loetakse TSV failist. Igast lausest tehakse *networkx* suunatud graaf. Graafi servadeks on süntaksipuu \n",
    "head->child seos. Tippudeks on lause sõnad. \n",
    "Tipu omadused on:\n",
    "* *id* - sõna id\n",
    "* deprel\n",
    "* lemma\n",
    "* pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 1000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 2000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 3000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 4000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 4999\n"
     ]
    }
   ],
   "source": [
    "\n",
    "unsaved = 0\n",
    "collocations = {}\n",
    "examples = {}\n",
    "word_id = 0\n",
    "count = 0\n",
    "current_sentence = []\n",
    "\n",
    "#\n",
    "G = None\n",
    "colId = None\n",
    "prevCol = 0\n",
    "with open(corporafile) as f:\n",
    "    for line in f:\n",
    "        count +=1\n",
    "        line = line.strip()\n",
    "        row = line.split('\\t')\n",
    "        if not len(row) == 8:\n",
    "            continue\n",
    "        data = {}\n",
    "        prevCol = colId\n",
    "        (colId, data['start'], data['id'], data['text'], data['lemma'], data['upostag'], data['deprel'], data['head']) = row\n",
    "        colId = int(colId)\n",
    "        for k in ('id', 'start', 'head'):\n",
    "            data[k] = int(data[k])\n",
    "\n",
    "        word_id +=1\n",
    "        #sentence start\n",
    "        if data['id'] == 1:\n",
    "            if not G==None:\n",
    "                current_sentence_text = ' '.join([s['text'] for s in current_sentence])\n",
    "                (collocations, examples) = extract_advmod(G, collocations, examples, current_sentence_text)\n",
    "                unsaved = 1\n",
    "            current_sentence = []\n",
    "            #count+=1\n",
    "            word_id +=1\n",
    "            G = nx.DiGraph()\n",
    "\n",
    "            if not prevCol ==colId and not colId==0 and not colId%BATCHSIZE:\n",
    "                saveCollToDb(collocations, examples, colId)\n",
    "                collocations = {}\n",
    "                unsaved = 0\n",
    "\n",
    "        #paneme graafi kokku\n",
    "        G.add_node(word_id, id=data['id'], lemma=data['lemma'], pos=data['upostag'], deprel=data['deprel'])\n",
    "        G.add_edge(word_id - data['id'] + data['head'], word_id, deprel = data['deprel'])\n",
    "        current_sentence.append(data)\n",
    "    \n",
    "    #viimane lause\n",
    "    current_sentence_text = ' '.join([s['text'] for s in current_sentence])\n",
    "    (collocations, examples) = extract_advmod(G, collocations, examples, current_sentence_text)\n",
    "    saveCollToDb(collocations, examples, colId)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andmebaasi indeksite lisamine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehakse kõige viimasena, et andmete sisestamine andmebaasi oleks kiirem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexesQ = [\n",
    "    f'CREATE INDEX IF NOT EXISTS \"lemma1\" ON \"{TABLENAME}\" (\"lemma1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"lemma2\" ON \"{TABLENAME}\" (\"lemma2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos1\" ON \"{TABLENAME}\" (\"pos1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos2\" ON \"{TABLENAME}\" (\"pos2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"total\" ON \"{TABLENAME}\" (\"total\" DESC);']\n",
    "\n",
    "for q in indexesQ: cursor.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"SELECT count(*) FROM {TABLENAME}\")\n",
    "all_collocations = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(78146,)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_collocations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
