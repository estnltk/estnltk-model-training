{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} pygraphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ülesande püstitus\n",
    "\n",
    "Proovime lihtsamat ülesannet. Vaata kuidas verb + määrsõna teiste nimisõnadega kombineerub\n",
    "    \n",
    "     kirjutas lepingule alla \n",
    "\n",
    "Ka siin tekib sul palju jama, sest sul võivad olla aja ja koha määrused sees, aga  proovi eraldada andmeid kujul\n",
    "\n",
    "kirjutas alla -->{lepingule:obl, jaanuaris:obl}\n",
    "kirjutas alla -->{dokumedile:obl}\n",
    "\n",
    "st jäta alles kõik lapstipud mis pole alus ja märgi ära ka vastav deprel annotatsioon\n",
    "\n",
    "Äkki õnnestub selle peale vaadates  osa ebaolulistest määrustest välja lõigata ja see subcat seos sealt välja õngitseda  \n",
    "\n",
    "\n",
    "## Täpsustus\n",
    "\n",
    "Võtame sisse nimisõnad, asesõnad, pärisnimed ja nende käänded\n",
    "Lisame info, kas verb oli eitusega (feat sisaldab neg väärtust). Kui on eitav, siis muudame verbi kujule \"ei VERB\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vajalikud teegid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import graphviz_layout\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "#import etnltk\n",
    "#from estnltk.storage.postgres import PostgresStorage\n",
    "\n",
    "import networkx as nx\n",
    "import sqlite3\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abifunktsioonid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class graphFunctions:\n",
    "\n",
    "    # kahe listi ühisosa \n",
    "    def intersection(a, b):\n",
    "        return list(set(a).intersection(b))\n",
    "\n",
    "    # tipu leidmine atribuudi väärtuse järgi\n",
    "    def get_nodes_by_attributes(G,  attrname, attrvalue ):\n",
    "        nodes = defaultdict(list)\n",
    "        {nodes[v].append(k) for k, v in nx.get_node_attributes(G,attrname).items()}\n",
    "        if attrvalue in nodes:\n",
    "            return dict(nodes)[attrvalue]\n",
    "        return []\n",
    "\n",
    "    # graafi joonistamine \n",
    "    # tipp - lemma\n",
    "    # serv - deprel\n",
    "    def drawGraph(G):\n",
    "        pos = graphviz_layout(G, prog='dot')\n",
    "        labels = nx.get_node_attributes(G, 'lemma')\n",
    "        nx.draw(G, pos, cmap = plt.get_cmap('jet'),labels=labels, with_labels=True)\n",
    "        edge_labels = nx.get_edge_attributes(G, 'deprel')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels)\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eprint(*args, **kwargs):\n",
    "    print(*args, file=sys.stderr, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCase(arr):\n",
    "    for attr in arr:\n",
    "        if attr in ('nom' #nimetav\n",
    "                    , 'gen' #omastav\n",
    "                    , 'part' #osastav\n",
    "                    , 'adit' #lyh sisse\n",
    "                    , 'ill' #sisse\n",
    "                    , 'in'#sees\n",
    "                    , 'el' #seest\n",
    "                    , 'ad' #alale\n",
    "                    , 'all' #alal\n",
    "                    , 'abl' #alalt\n",
    "                    , 'tr' #saav\n",
    "                    , 'term' #rajav\n",
    "                    , 'es' #olev\n",
    "                    , 'abes'  #ilma#\n",
    "                    , 'kom' #kaasa#\n",
    "                   ) :\n",
    "            return attr\n",
    "\n",
    "def getNumber(arr):\n",
    "    for attr in arr:\n",
    "        if attr in ('sg' #ainsus\n",
    "                    , 'pl' #mitmus\n",
    "                   ):\n",
    "            return attr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baasi  (sqlite3)  ettevalmistamine täitmiseks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luuakse tabelid:\n",
    "* collections_processed - salvestatakse viimane salvestatud collection Id\n",
    "* {TABLENAME} - tabel kollokatsioonidega\n",
    " * lemma1 text\n",
    " * pos1 text\n",
    " * lemma2 text\n",
    " * pos2 text\n",
    " * deprel text\n",
    " * children json\n",
    " * total integer\n",
    " * example1 text\n",
    " * example2 text\n",
    " * example3 text\n",
    "\n",
    "Luuakse indeksid:\n",
    "* collections_processed_uniq\n",
    "* {TABLENAME}_col1_col2_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepCollDb():\n",
    "    global TABLENAME, cursor, conn\n",
    "\n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS collections_processed\n",
    "                      (tablename text, lastcollection integer);\n",
    "                      \"\"\")\n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS collections_processed_uniq ON collections_processed(tablename);\n",
    "    \"\"\")\n",
    "    \n",
    "    #tsv failist lugemise korral loome tabeli alati nullist\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO collections_processed VALUES (?,?)\n",
    "        ON CONFLICT(tablename) DO UPDATE SET lastcollection=?;\"\"\", (TABLENAME, 0, 0,) )\n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS all_in_one\n",
    "                      (lemma1 text, pos1 text, lemma2 text, pos2 text, deprel text, children json, total integer, example1 text, example2 text, example3 text);\n",
    "                      \"\"\")\n",
    "\n",
    "    #cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS collocations\n",
    "    #                  (lemma1 text, pos1 text, lemma2 text, pos2 text, total integer, deprel);\n",
    "    #                  \"\"\")\n",
    "\n",
    "    #cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS children\n",
    "    #                  (lemma text, pos text, lemma_case text, case_lemma text, case_pos text, deprel text, total integer);\n",
    "    #                  \"\"\")\n",
    "\n",
    "    #cursor.execute(f\"\"\"CREATE TABLE IF NOT EXISTS collections\n",
    "    #                  (coll_id integer, childrens text, total integer);\n",
    "    #                  \"\"\")\n",
    "        \n",
    "    #tsv failist lugemise korral loome tabeli alati nullist\n",
    "    #cursor.execute(f\"\"\"DELETE FROM collocations;\"\"\")\n",
    "    #cursor.execute(f\"\"\"DELETE FROM children;\"\"\")\n",
    "    #cursor.execute(f\"\"\"DELETE FROM collections;\"\"\")\n",
    "    cursor.execute(f\"\"\"DELETE FROM all_in_one;\"\"\")\n",
    "    \n",
    "    INDEXNAME = f'col1_col2_unique'\n",
    "    \n",
    "    cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}_all_in_one\n",
    "        ON all_in_one(lemma1, pos1, lemma2, pos2, deprel, children);\n",
    "        \"\"\")\n",
    "    \n",
    "    #cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}_collocations\n",
    "    #    ON collocations(lemma1, pos1, lemma2, pos2, deprel);\n",
    "    #    \"\"\")\n",
    "    \n",
    "    #cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}_children\n",
    "    #    ON children(lemma, pos, lemma_case, case_lemma, case_pos, deprel);\n",
    "    #    \"\"\")\n",
    "    \n",
    "    #cursor.execute(f\"\"\"CREATE UNIQUE INDEX IF NOT EXISTS {INDEXNAME}_collections\n",
    "    #    ON collections(coll_id, childrens);\n",
    "    #    \"\"\")\n",
    "   \n",
    "    conn.commit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tulemuse salvestamine baasi (sqlite3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveCollToDb(collocations, examples, lastcollection):\n",
    "    global TABLENAME, cursor, conn\n",
    "    sqlColls = []\n",
    "    #print ('here', collections)\n",
    "    \n",
    "    for key in collections.keys():\n",
    "        #print ('key', key)\n",
    "        #save key in parents or update count, get rowid\n",
    "        \n",
    "        #lemma1 text, pos1 text, lemma2 text, pos2 text, total integer, deprel\n",
    "     \n",
    "        example1 = None\n",
    "        example2 = None\n",
    "        example3 = None\n",
    "\n",
    "        if len(examples[key])>0:\n",
    "            example1 = examples[key][0]\n",
    "        if len(examples[key])>1:\n",
    "            example2 = examples[key][1]\n",
    "        if len(examples[key])>2:\n",
    "            example3 = examples[key][2]\n",
    "        \n",
    "        lemma1 = key[0]\n",
    "        pos1 = key[2]\n",
    "        lemma2 = key[1]\n",
    "        pos2 = key[3]\n",
    "        deprel = key[4]\n",
    "        children = key[5]\n",
    "        \n",
    "        sqlColls.append( (lemma1, pos1, lemma2,  pos2, deprel, children, collocations[key], example1, example2, example3 , collocations[key], example1, example2,example3,) )\n",
    "\n",
    "        \n",
    "    cursor.executemany(f\"\"\"\n",
    "        INSERT INTO all_in_one VALUES (?,?,?,?,?,?,?,?,?,?)\n",
    "            ON CONFLICT(lemma1, pos1, lemma2, pos2, deprel, children)\n",
    "            DO UPDATE SET total=total+? \n",
    "            ,  example1= ?\n",
    "            ,  example2= ?\n",
    "            ,  example3= ?\n",
    "            ;\"\"\", sqlColls)\n",
    "\n",
    "    cursor.execute(f\"\"\"\n",
    "        INSERT INTO collections_processed VALUES (?,?)\n",
    "        ON CONFLICT(tablename) DO UPDATE SET lastcollection=?;\"\"\", (TABLENAME, lastcollection, lastcollection,) )\n",
    "    \n",
    "           \n",
    "   \n",
    "    conn.commit()\n",
    "    eprint(f'andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - {lastcollection}' )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  sõltuvuste leidmine \n",
    "\n",
    "* Kõik kolmikud, kus \n",
    "    * ülemus on tipp1 sõnaliigiga V ja alluv on tipp2 D \n",
    "    * ülemusel tipp1 on nimisõna/asesõna/pärisnimi (S/P/H) alluv, selle deprel ja kääne \n",
    "\n",
    "#### Näide 1\n",
    "\n",
    "tõmbama\tV\tvarem\tD\tadvmod\n",
    "\n",
    "<img src=\"img/all_deprel_verb_advberb_01.png\" width=\"600\" />\n",
    "\n",
    "###Näide 2\n",
    "\n",
    "saama\tV\tvälja\tD\tcompound:prt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_verb_adverb_custom_deprel(G, collocations, examples, sentence):\n",
    "   \n",
    "    \n",
    "    #graphFunctions.drawGraph(G)\n",
    "    #print (sentence)\n",
    "    # lyhim tee tippude vahel\n",
    "    path = nx.all_pairs_shortest_path_length(G)\n",
    "    path_reversed = nx.all_pairs_shortest_path_length(G.reverse())\n",
    "\n",
    "    # kauguste maatriksid\n",
    "    dpath = {x[0]:x[1] for x in path}\n",
    "    dpath_reversed = {x[0]:x[1] for x in path}\n",
    "\n",
    "    #eprint('eraldame tipud vajalike parameetritega ')\n",
    "    verbnodes = graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'V')\n",
    "    \n",
    "    adverbnodes = graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'D')\n",
    "    #vb on olulised ka pärisnimed ning asesõnad?\n",
    "    nouns = graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'S') + graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'H')+ graphFunctions.get_nodes_by_attributes(G, attrname = 'pos', attrvalue = 'P')\n",
    "    \n",
    "    cases = graphFunctions.get_nodes_by_attributes(G, attrname = 'deprel', attrvalue = 'case')\n",
    "    \n",
    "    #print ('cases', cases)\n",
    "    #liigume tegusõnade kaupa\n",
    "    \n",
    "    #tekitame kollokatsioonipaari sellise:\n",
    "    #Isa hülgas Jimmy kohe pärast tema sündi .\n",
    "    # hülgama -[ advmod ]-> kohe sellel on id ja count?\n",
    "    # children: obj Jimmy H nom\n",
    "    # children: obj sünd S com pärast D\n",
    "        #-[ obj ]-> Jimmy nom\n",
    "\n",
    "        #-[ obl ]-> sündi com -[ case ]-> pärast\n",
    "    \n",
    "    for verb in verbnodes:\n",
    "        childadverbs = []\n",
    "        childnouns = []\n",
    "        for adverb in adverbnodes:\n",
    "            #kui on vahetu alluv\n",
    "            if adverb in dpath[verb] and dpath[verb][adverb]==1: childadverbs.append(adverb)\n",
    "        for noun in nouns:\n",
    "            #kui on vahetu alluv\n",
    "            # subj j2tame v2lja\n",
    "            # kas siin peab ka nsubj:coop ja ssubj:coop olema?\n",
    "            if G.nodes[noun]['deprel'] in ['nsubj', 'csubj']: continue\n",
    "            if noun in dpath[verb] and dpath[verb][noun]==1: childnouns.append(noun)\n",
    "        \n",
    "        for adverb in childadverbs:\n",
    "            \n",
    "            #print ('collocation', key)\n",
    "            children = []\n",
    "            for noun in childnouns:\n",
    "                child = {\n",
    "                        'lemma': G.nodes[noun]['lemma']\n",
    "                        , 'pos': G.nodes[noun]['pos']\n",
    "                        , 'case':getCase(G.nodes[noun]['feat'])\n",
    "                        , 'number':getNumber(G.nodes[noun]['feat'])\n",
    "                        , 'deprel': G.nodes[noun]['deprel']\n",
    "                        , 'case_children':[]\n",
    "                        }\n",
    "                #print (\"\\t\" '-[',G.nodes[noun]['deprel'],']->', G.nodes[noun]['text'], getCase(G.nodes[noun]['feat']))\n",
    "                #print ()\n",
    "                childcases = []\n",
    "                for case in cases:\n",
    "                    if case in dpath[noun] and dpath[noun][case]==1: \n",
    "                        child['case_children'].append( (G.nodes[case]['lemma'], G.nodes[case]['pos'], ) )\n",
    "                        \n",
    "                        \n",
    "               \n",
    "                    \n",
    "                \n",
    "                children.append(child)\n",
    "           \n",
    "            key = ( 'ei ' + G.nodes[verb]['lemma'] if 'neg' in G.nodes[verb]['feat']  else G.nodes[verb]['lemma'], G.nodes[adverb]['lemma'], G.nodes[verb]['pos'], G.nodes[adverb]['pos'], G.nodes[adverb]['deprel'], json.dumps(children) ,)\n",
    "\n",
    "                #synFunctions.drawGraph(G);\n",
    "                #key = (G.nodes[verb]['lemma'], G.nodes[adverb]['lemma'], G.nodes[verb]['pos'], G.nodes[adverb]['pos'], G.nodes[adverb]['deprel'], )\n",
    "                \n",
    "               \n",
    "            if not key in collocations:\n",
    "                collocations[key] = 0\n",
    "            if not key in examples:\n",
    "                examples[key] = []\n",
    "            collocations[key] += 1\n",
    "            examples[key].append(sentence)\n",
    "            if len(examples[key]) > 3:\n",
    "                del(examples[key][random.randint(0, 2)])\n",
    "                \n",
    "                #if len(child['case_children'])>1: \n",
    "                #    print ('many cases',   key)\n",
    "                #    graphFunctions.drawGraph(G)\n",
    "            \n",
    "    #print (collections)\n",
    "    return (collocations, examples)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Muutujad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Korpuse TSV fail**\n",
    "\n",
    "Lähte TSV-faili ja DB tabeli nimi, kuhu tulemus salvestatakse (TSV genereerimise kood on failis **collect_texts_db_tsv.ipynb**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectionName =  'koondkorpus_base_v2_20220216' \n",
    "#collectionName =  'koondkorpus_base_subset_of_5000_v2' \n",
    "corporafile = f'{collectionName}.tsv'\n",
    "corporafile = '/Volumes/Selena/Kollokatsioonid/koondkorpus/koondkorpus_base_v2_20220216.tsv'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollokatsiooni tüüp**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TYPE = 'kadrile_verb_adverb_noun_deprel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tabeli nimi andmebaasis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TABLENAME = f'{TYPE}_{collectionName}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kollektsioonide arv**, mille kaupa salvestatakse vahepealne tulemus andmebaasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 6000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Andmebaasi loomine ja ette valmistamine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(f\"{TYPE}_collocations.db\") #\n",
    "cursor = conn.cursor()\n",
    "prepCollDb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kollokatsioonide leidmine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andmed loetakse TSV failist. Igast lausest tehakse *networkx* suunatud graaf. Graafi servadeks on süntaksipuu \n",
    "head->child seos. Tippudeks on lause sõnad. \n",
    "Tipu omadused on:\n",
    "* *id* - sõna id\n",
    "* deprel\n",
    "* lemma\n",
    "* pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 6000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 12000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 18000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 24000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 30000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 36000\n",
      "andmebaasi salvestatud kollokatsioonid kollektsioonidest: 0 - 42000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-221420456337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m                 \u001b[0mcurrent_sentence_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcurrent_sentence\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0;34m(\u001b[0m\u001b[0mcollections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_verb_adverb_custom_deprel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcollocations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_sentence_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0munsaved\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mcurrent_sentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-5acb952da189>\u001b[0m in \u001b[0;36mextract_verb_adverb_custom_deprel\u001b[0;34m(G, collocations, examples, sentence)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# lyhim tee tippude vahel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_pairs_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpath_reversed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_pairs_shortest_path_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# kauguste maatriksid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36mreverse\u001b[0;34m(self, copy)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36madd_nodes_from\u001b[0;34m(self, nodes_for_adding, **attr)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m         \"\"\"\n\u001b[0;32m--> 469\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnodes_for_adding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;31m# keep all this inside try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;31m# CPython throws TypeError on n not in self._succ,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/site-packages/networkx/classes/digraph.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_nodes_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m             \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_edges_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/copy.py\u001b[0m in \u001b[0;36m_deepcopy_dict\u001b[0;34m(x, memo, deepcopy)\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mmemo\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/rumorf37/lib/python3.7/copy.py\u001b[0m in \u001b[0;36mdeepcopy\u001b[0;34m(x, memo, _nil)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mcopier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_deepcopy_dispatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "unsaved = 0\n",
    "collocations = {}\n",
    "examples = {}\n",
    "word_id = 0\n",
    "count = 0\n",
    "current_sentence = []\n",
    "\n",
    "#\n",
    "G = None\n",
    "colId = None\n",
    "prevCol = 0\n",
    "\n",
    "\n",
    "with open(corporafile) as f:\n",
    "    for line in f:\n",
    "        count +=1\n",
    "        line = line.strip(\"\\n\")\n",
    "        row = line.split('\\t')\n",
    "        if not len(row) == 9:\n",
    "            continue\n",
    "        data = {}\n",
    "        prevCol = colId\n",
    "        (colId, data['start'], data['id'], data['text'], data['lemma'], data['upostag'], data['deprel'], data['head'], data['feat']) = row\n",
    "        colId = int(colId)\n",
    "        for k in ('id', 'start', 'head'):\n",
    "            data[k] = int(data[k])\n",
    "\n",
    "        word_id +=1\n",
    "        #sentence start\n",
    "        if data['id'] == 1:\n",
    "            if not G==None:\n",
    "                current_sentence_text = ' '.join([s['text'] for s in current_sentence])\n",
    "                (collections, examples) = extract_verb_adverb_custom_deprel(G, collocations, examples, current_sentence_text)\n",
    "                unsaved = 1\n",
    "            current_sentence = []\n",
    "            #count+=1\n",
    "            word_id +=1\n",
    "            G = nx.DiGraph()\n",
    "            if not prevCol ==colId and not colId==0 and not colId%BATCHSIZE:\n",
    "                saveCollToDb(collocations, examples, colId)\n",
    "                collocations = {}\n",
    "                unsaved = 0\n",
    "\n",
    "\n",
    "        #paneme graafi kokku\n",
    "        G.add_node(word_id, id=data['id'], text=data['text'],  lemma=data['lemma'], pos=data['upostag'], deprel=data['deprel'], feat=data['feat'].split('||'))\n",
    "        G.add_edge(word_id - data['id'] + data['head'], word_id, deprel = data['deprel'])\n",
    "        current_sentence.append(data)\n",
    "        \n",
    "        \n",
    "    \n",
    "    #viimane lause\n",
    "    current_sentence_text = ' '.join([s['text'] for s in current_sentence])\n",
    "    (collocations, examples) = extract_verb_adverb_custom_deprel(G, collocations, examples, current_sentence_text)\n",
    "    saveCollToDb(collocations, examples, colId)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Andmebaasi indeksite lisamine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tehakse kõige viimasena, et andmete sisestamine andmebaasi oleks kiirem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "indexesQ = [\n",
    "    f'CREATE INDEX IF NOT EXISTS \"deprel\" ON all_in_one (\"deprel\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"lemma1\" ON all_in_one (\"lemma1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"lemma2\" ON all_in_one(\"lemma2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos1\" ON all_in_one (\"pos1\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"pos2\" ON all_in_one (\"pos2\");'\n",
    "    , f'CREATE INDEX IF NOT EXISTS \"total\" ON all_in_one (\"total\" DESC);']\n",
    "\n",
    "for q in indexesQ: cursor.execute(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"SELECT count(*) FROM all_in_one\")\n",
    "all_collocations = cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(600148,)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_collocations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
